{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i1jd4XY24VTY"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3slV2Vpk4pmf"
      },
      "outputs": [],
      "source": [
        "# Set the path to your dataset\n",
        "dataset_path = 'drive/MyDrive/Vanderbilt/SSDA/ML/Image classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BXz2W00A42mY"
      },
      "outputs": [],
      "source": [
        "# Categories for classification\n",
        "categories = ['recto', 'verso', 'double']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YjseFGru49bZ"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess the images\n",
        "def load_images(dataset_path, categories, image_size=(150, 150)):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for category in categories:\n",
        "        path = os.path.join(dataset_path, category)\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            try:\n",
        "                # Load image, convert to grayscale, resize, and normalize\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                img = cv2.resize(img, image_size)\n",
        "                img = img / 255.0\n",
        "                data.append(img)\n",
        "                labels.append(category)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_name}: {e}\")\n",
        "\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QsD_xok65Jo6"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "X, y = load_images(dataset_path, categories)\n",
        "X = np.expand_dims(X, axis=-1)  # add channel dimension (for grayscale images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zuEpwlsu6t2k"
      },
      "outputs": [],
      "source": [
        "# Encode labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_encoded = to_categorical(y_encoded, num_classes=len(categories))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "flEM8M-H7LR8"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PpxsY2c47SAU"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model using Input()\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Input(shape=(150, 150, 1)))  # 150x150 image with 1 channel for grayscale\n",
        "\n",
        "# Add convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu')) # captures basic features like edges and corners, ReLU introduces non-linearity\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # downsamples feature maps to increase computational efficiency and prevent overfitting\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu')) # increases number of filters to allow model to learn more detailed features\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten and fully connected layers\n",
        "model.add(Flatten()) # converts 2D feature maps to 1D vectors to connect convolutional layers to fully connected layers\n",
        "model.add(Dense(128, activation='relu')) # combines features learned in convolutional layers to make predictions\n",
        "model.add(Dropout(0.5)) # randomly \"drops\" 50% of the neurons in the fully connected layer to prevent overfitting\n",
        "model.add(Dense(len(categories), activation='softmax')) # predicts the class with highest probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FbA67YBuNaKv"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # Adaptive Moment Estimation and categorical cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E9nTwgXGPH4g"
      },
      "outputs": [],
      "source": [
        "# Data augmentation to enhance training\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,  # Disable horizontal flip to avoid label ambiguity\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxZKzllYPOwG",
        "outputId": "f57005b2-9543-47dd-daaf-d26e0c0db218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.8719 - loss: 0.4591 - val_accuracy: 1.0000 - val_loss: 0.1888\n",
            "Epoch 2/15\n",
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9643 - loss: 0.2183"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - accuracy: 0.9643 - loss: 0.2183 - val_accuracy: 1.0000 - val_loss: 0.1933\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9917 - loss: 0.2033 - val_accuracy: 1.0000 - val_loss: 0.0954\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.1491 - val_accuracy: 1.0000 - val_loss: 0.0609\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0828 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step - accuracy: 0.8929 - loss: 0.1533 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9917 - loss: 0.0390 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9719 - loss: 0.0559 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 147ms/step - accuracy: 0.9643 - loss: 0.0677 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9917 - loss: 0.0253 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 155ms/step - accuracy: 1.0000 - loss: 0.0350 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9969 - loss: 0.0284 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 157ms/step - accuracy: 0.9643 - loss: 0.0394 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 9.5289e-04\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    steps_per_epoch=len(X_train) // batch_size,\n",
        "                    epochs=epochs)\n",
        "\n",
        "# Save the model\n",
        "model.save('folio_classifier_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCb8R870RQzQ",
        "outputId": "909b7193-4035-459d-f86b-4aa586ee366e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 9.7197e-04\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "em5g8h56Rxhd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Define a function to preprocess the input image and predict the class label\n",
        "def predict_folio_class(image_path, model):\n",
        "    # Define the image size your model was trained on (150x150 in this case)\n",
        "    image_size = (150, 150)\n",
        "\n",
        "    # Load the image from the provided path, convert to grayscale\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize the image to match the input size of the model\n",
        "    image = cv2.resize(image, image_size)\n",
        "\n",
        "    # Convert the image to a numpy array and normalize pixel values\n",
        "    image = img_to_array(image) / 255.0\n",
        "\n",
        "    # Expand dimensions to fit the model input shape (1, 150, 150, 1)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Use the model to predict the class label probabilities\n",
        "    predictions = model.predict(image)\n",
        "\n",
        "    # Get the index of the highest probability\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # Define the class labels (these should match your training labels)\n",
        "    class_labels = ['double', 'recto', 'verso']\n",
        "\n",
        "    # Map the predicted index to the corresponding class label\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    return predicted_class_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JzKk6v3jR2jX",
        "outputId": "7a4f13cf-bfd7-4f7a-9dd5-113c10f4ad23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'recto'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_folio_class(\"drive/MyDrive/Vanderbilt/SSDA/ML/Image classification/recto/239746-0041.jpg\", model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
